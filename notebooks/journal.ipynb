{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "* Trying to implement normalization algorithm\n",
    "    * It's giving me all nan for some reason\n",
    "    * I think the numbers are too big? trying 64 bit floats\n",
    "    * I'm trying subsets of the array. The numbers top out at like 26000 before going Nan. Wtf? I know float64 goes *way* higher than that\n",
    "    * Ohhhh there are Nans in the array. Let's make sure that doesn't happen.\n",
    "    * Alright, it's working but it's still very slow. I'm not sure if it's working correctly as well.\n",
    "    * Well let's start by cropping the image...\n",
    "    * Ugh... I've been trying this for hours now. Fuck this, i'm gonna try something else\n",
    "    * Alright, I implemented a bunch of different stuff. I'm a little concerned because all of them are quite slow. I can't get beyond 15 FPS. Constant normalization may not be an option.\n",
    "* I tried a bunch to implement corner detection for the field\n",
    "    * Not going too well lol\n",
    "    * Tried 3 different methods, honestly rn the line based one is looking most promising but needs a lot of work\n",
    "    * For now I'm doing it manually so I can move on to more important stuff\n",
    "* Talked with professor she gave some ideas\n",
    "* We still don't know what's wrong with the comprehensive normalizer (if anything)\n",
    "* Working on field detection while reimplemented processor runs\n",
    "    * Hough lines is a mess, maybe it would work if I tuned it\n",
    "    * Line segment detector performed much better off the bat so i'm going to start tuning that\n",
    "    * It works really well! I might need to do some distortion correction for best results\n",
    "    * The one issue is that due to robots in the way I can really only detect the upper lines of the field. In order to get the really nice overhead view that can track robot positions I'm gonna need to do something else.\n",
    "    * I also made the line detector more robust. It now doesn't just give up and die if it doesn't see the field immediately\n",
    "    * LCN normalization isn't a good bet for detecting grey stuff. In some videos the field turns out more blue (especially in wisconsin videos)\n",
    "    * Comprehensive was the way to go. We're all good with this now!\n",
    "* Robot detection and tracking\n",
    "    * Experimenting with built in trackers - a proper initial selections seems to be important\n",
    "        * MIL - Partial occlusions good, rotation and scaling good, haven't seen full occlusions yet, failed with going over the barrier and lines sometimes, not sure why. Maybe due to the full occlusion right after.\n",
    "        * MedianFlow didn't work\n",
    "        * KCF can't handle rotations\n",
    "        * MOSSE didn't work\n",
    "        * CSRT - Handled rotations alright, partial occlusions look good, track gets a little off center, speed is good, lost track after full occlusion\n",
    "        * Boosting - Track got off center for a bit but rotations look good, jittery and seems to have lost track after partial occlusion (kinda my fault though i initialized it weird), imprecise but surprisingly resilient, lost track after full occlusion\n",
    "        * TLD didn't work\n",
    "        * GOTURN - loses the track pretty quickly, probably not designed for robots, lol\n",
    "* I haven't done cube tracking but storage tracking is done\n",
    "    * I'm tracking the entire alliance hub. We'll figure out how to know what level things are on later.\n",
    "        * Likely going to look at top third, middle third, bottom third\n",
    "        * That's the easy part though lol, still need to figure out how to track or detect these cubes\n",
    "    * I decided to use the KCF tracker as it's plenty fast and accurate\n",
    "    * Even higher speeds can be achieved by only updating the tracker once every 3 or 4 frames\n",
    "    * Testing on some other videos\n",
    "        * Needed modification for wisconsin to avoid detecting blue line (checking aspect ratio now)\n",
    "        * While testing found error in perspective detector: match-wisconsin.mp4-252965-257735.mp4\n",
    "        * Unfortunately the tracker gets confused with obstructions. Track fail: match-wisconsin.mp4-158349-163119.mp4\n",
    "    * Man, I haven't journaled in a while, here's a rundown of everything that happened\n",
    "        * I've been trying to implement that connected object separation method, but the paper is quite confusing so I haven't gotten anywhere yet\n",
    "        * Detecting items on the alliance hubs is quite hard due to shadows and stuff. I might try mean subtraction later or like something similar\n",
    "        * I've gotten somewhere by using a knn based segmentation method (not kmeans, but knn since we know kinda what colors we're looking for)\n",
    "        * Object segmentation kind of working, i'm gonna try to generate the hull distance value dynamically"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}